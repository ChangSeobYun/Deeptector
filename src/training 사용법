./openpose-darknet train forder이름 openpose.cfg openpose.weights 0 

맨 마지막 0은 연속적인 동작 - 한 비디오로 학습데이터를 뽑을 수 있는 것만 가능
(hello, hold, walk) 세개정도...?


data/학습클래스로 폴더 만들고 그폴더에 데이터 넣으면 됨
그 후 위의 명령어로 돌리면 csv/폴더에 data.csv로 저장됨

우선 시간상 데모 영상에서는 학습하기 쉬운 hello랑 hold만 넣을 예정
가만있는거랑 안녕하는거 동영상 조금 길게 찍은 후
가만히 서있는건 그냥 돌리기만 하면 되는데
문제는 hello 이게 지금 손이 좌표가 왔다갔다 하면서 학습이 안됨... 
따라서 hello는 손 위치의 시작점에 따라 클래스를 여러개로 나누어야 할 것 같음....
hello 영상 넣은 후에 위의 명령어 쳐서 데이터 뽑고 뽑은데이터를 일일이 눈으로 확인하면서 똑같은 지점을 찾아서 각각 학습시켜야 할 것 같아....

힘들 거 같으면 우선 안녕할 때 최대한 똑같은 속도로 손 흔들고 (우선 정면만...) 최대한 길게 동영상만 찍어주면 내가 해볼게... 

어려울 것 같으면 PPT를 조금만 손봐주고...! 저번 PPT에 RNN부분만 추가해서 발표해버릴라고...
RNN부분은 그 팜플렛에 넣었던 그림으로 그냥 설명하고 끝낼까 생각중... 조금 더 추가하거나...
우선 이거 확인하면 연락을 주렴...ㅠㅠㅠ큨ㅋㅋㅋㅋ
